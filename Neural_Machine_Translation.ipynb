{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Machine Translation",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgXGcRHcaf4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import collections\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzG7r_gYY5wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, CuDNNLSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7MAT_jbaJkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(path):\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = f.read()\n",
        "    return data.split('\\n')\n",
        "\n",
        "def process_data(data):\n",
        "    new_sentence = []\n",
        "    for sentence in data:\n",
        "        clean = re.compile('<.*>')\n",
        "        new_sentence.append(re.sub(clean, '', sentence))\n",
        "    del new_sentence[-2:]\n",
        "    return new_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DvflehKbt1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english = process_data(load_data('/content/small_vocab_en.txt'))\n",
        "french = process_data(load_data('/content/small_vocab_fr.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDbmV1Gbx5ZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ed6fd72c-b995-4f42-d6cb-763a0408ee6e"
      },
      "source": [
        "english_words_counter = collections.Counter([word for sentence in english for word in sentence.split(\" \")])\n",
        "print(\"Total no. of words in english: \", len([word for sentence in english for word in sentence.split(\" \")]))\n",
        "print(\"Total no. of unique words: \", len(english_words_counter))\n",
        "\n",
        "french_words_counter = collections.Counter([word for sentence in french for word in sentence.split(\" \")])\n",
        "print(\"Total no. of words in french: \", len([word for sentence in french for word in sentence.split(\" \")]))\n",
        "print(\"Total no. of unique words: \", len(french_words_counter))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of words in english:  1823292\n",
            "Total no. of unique words:  228\n",
            "Total no. of words in french:  1961298\n",
            "Total no. of unique words:  356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pmubzcQyRCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(x):\n",
        "    tk = Tokenizer(char_level = False)\n",
        "    tk.fit_on_texts(x)\n",
        "    return tk.texts_to_sequences(x), tk\n",
        "\n",
        "def pad(x, length=None):\n",
        "    if length is None:\n",
        "        length = max([len(sentence) for sentence in x])\n",
        "    return pad_sequences(x, maxlen = length, padding = 'post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ly8GJSt2cQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "    data_x, x_tk = tokenize(x)\n",
        "    data_y, y_tk = tokenize(y)\n",
        "\n",
        "    data_x = pad(data_x)\n",
        "    data_y = pad(data_y)\n",
        "\n",
        "    data_y = data_y.reshape(*data_y.shape, 1)\n",
        "\n",
        "    return data_x, data_y, x_tk, y_tk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4WUXPQK2fKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_english, processed_french, english_tokenizer, french_tokenizer = preprocess(english, french)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8HzpTbL3pKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a4de514f-3867-4fbf-b719-36b59dcdc3f5"
      },
      "source": [
        "max_english_sequence_length = processed_english.shape[1]\n",
        "max_french_sequence_length = processed_french.shape[1]\n",
        "print(max_english_sequence_length)\n",
        "print(max_french_sequence_length)\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9p1487F53nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBNpB3zX9AAv",
        "colab_type": "text"
      },
      "source": [
        "#**Simple RNN**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fghr4Z1s6PyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_model(input_shape, french_vocab_size):\n",
        "    input_seq = Input(input_shape[1:])\n",
        "    rnn = GRU(64, return_sequences = True)(input_seq)\n",
        "    logits = TimeDistributed(Dense(french_vocab_size))(rnn)\n",
        "\n",
        "    model = Model(input_seq, Activation('softmax')(logits))\n",
        "    model.compile(loss = sparse_categorical_crossentropy, optimizer = Adam(1e-3), metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBE1hlmJ2dg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_x = pad(processed_english, max_french_sequence_length)\n",
        "tmp_x = tmp_x.reshape((-1, processed_french.shape[-2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKLyZ3K74TCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "59eb627e-f2e4-41c1-9150-1707758fa838"
      },
      "source": [
        "simple_rnn_model = simple_model(tmp_x.shape, french_vocab_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0625 08:47:12.225424 140256952489856 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frg8CuM05MnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5f38ac56-71d4-41af-bac3-8609b498fa50"
      },
      "source": [
        "simple_rnn_model.fit(tmp_x, processed_french, batch_size=1024, epochs=30, validation_split=0.2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0625 08:47:12.639853 140256952489856 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 110288 samples, validate on 27572 samples\n",
            "Epoch 1/30\n",
            "110288/110288 [==============================] - 8s 77us/sample - loss: 3.5501 - acc: 0.4149 - val_loss: nan - val_acc: 0.4718\n",
            "Epoch 2/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 2.3920 - acc: 0.4763 - val_loss: nan - val_acc: 0.5028\n",
            "Epoch 3/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 2.1528 - acc: 0.5314 - val_loss: nan - val_acc: 0.5567\n",
            "Epoch 4/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.9074 - acc: 0.5661 - val_loss: nan - val_acc: 0.5820\n",
            "Epoch 5/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.7454 - acc: 0.5827 - val_loss: nan - val_acc: 0.5855\n",
            "Epoch 6/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.6439 - acc: 0.5910 - val_loss: nan - val_acc: 0.5953\n",
            "Epoch 7/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.5732 - acc: 0.5996 - val_loss: nan - val_acc: 0.6043\n",
            "Epoch 8/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.5175 - acc: 0.6062 - val_loss: nan - val_acc: 0.6100\n",
            "Epoch 9/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.4696 - acc: 0.6176 - val_loss: nan - val_acc: 0.6223\n",
            "Epoch 10/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.4280 - acc: 0.6252 - val_loss: nan - val_acc: 0.6297\n",
            "Epoch 11/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.3918 - acc: 0.6310 - val_loss: nan - val_acc: 0.6349\n",
            "Epoch 12/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.3592 - acc: 0.6370 - val_loss: nan - val_acc: 0.6398\n",
            "Epoch 13/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.3290 - acc: 0.6405 - val_loss: nan - val_acc: 0.6425\n",
            "Epoch 14/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.3012 - acc: 0.6432 - val_loss: nan - val_acc: 0.6438\n",
            "Epoch 15/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.2763 - acc: 0.6461 - val_loss: nan - val_acc: 0.6472\n",
            "Epoch 16/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.2532 - acc: 0.6493 - val_loss: nan - val_acc: 0.6510\n",
            "Epoch 17/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.2326 - acc: 0.6520 - val_loss: nan - val_acc: 0.6532\n",
            "Epoch 18/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.2145 - acc: 0.6545 - val_loss: nan - val_acc: 0.6556\n",
            "Epoch 19/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.1981 - acc: 0.6559 - val_loss: nan - val_acc: 0.6569\n",
            "Epoch 20/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.1840 - acc: 0.6574 - val_loss: nan - val_acc: 0.6575\n",
            "Epoch 21/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.1703 - acc: 0.6591 - val_loss: nan - val_acc: 0.6600\n",
            "Epoch 22/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.1582 - acc: 0.6604 - val_loss: nan - val_acc: 0.6605\n",
            "Epoch 23/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.1470 - acc: 0.6621 - val_loss: nan - val_acc: 0.6626\n",
            "Epoch 24/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.1365 - acc: 0.6630 - val_loss: nan - val_acc: 0.6627\n",
            "Epoch 25/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.1264 - acc: 0.6636 - val_loss: nan - val_acc: 0.6640\n",
            "Epoch 26/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.1168 - acc: 0.6648 - val_loss: nan - val_acc: 0.6670\n",
            "Epoch 27/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.1072 - acc: 0.6665 - val_loss: nan - val_acc: 0.6671\n",
            "Epoch 28/30\n",
            "110288/110288 [==============================] - 8s 71us/sample - loss: 1.0990 - acc: 0.6673 - val_loss: nan - val_acc: 0.6711\n",
            "Epoch 29/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.0898 - acc: 0.6696 - val_loss: nan - val_acc: 0.6726\n",
            "Epoch 30/30\n",
            "110288/110288 [==============================] - 8s 70us/sample - loss: 1.0814 - acc: 0.6705 - val_loss: nan - val_acc: 0.6744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8fd28eb390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBxC91Qa6-Zm",
        "colab_type": "code",
        "outputId": "6ed095ec-d08e-48a5-b9b9-5798a8dd1afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new jersey est parfois calme en mois de et il il est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl6BsgiW9M0Q",
        "colab_type": "text"
      },
      "source": [
        "#**Using Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6jwTPqz-ge4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embedding_model(input_shape, french_vocab_size):\n",
        "    embedding = Embedding(french_vocab_size, 64, input_length = input_shape[1])\n",
        "    rnn = GRU(64, return_sequences = True, activation='tanh')\n",
        "    logits = TimeDistributed(Dense(french_vocab_size, activation='softmax'))\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(embedding)\n",
        "    model.add(rnn)\n",
        "    model.add(logits)\n",
        "    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(1e-3),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuEisCk-BRkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_x = pad(processed_english, max_french_sequence_length)\n",
        "tmp_x = tmp_x.reshape((-1, processed_french.shape[-2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDzF9NoWBtaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "322ad198-225e-4a8a-db09-cc1dcc720d7e"
      },
      "source": [
        "simple_embedd_model = embedding_model(tmp_x.shape, french_vocab_size)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0625 08:51:08.874375 140256952489856 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCnEdoukC9iJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a7e0c868-ee70-408f-8836-ee9f518702f5"
      },
      "source": [
        "simple_embedd_model.fit(tmp_x, processed_french, batch_size=1024, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 110288 samples, validate on 27572 samples\n",
            "Epoch 1/10\n",
            "110288/110288 [==============================] - 9s 77us/sample - loss: 3.7455 - acc: 0.4017 - val_loss: nan - val_acc: 0.4093\n",
            "Epoch 2/10\n",
            "110288/110288 [==============================] - 8s 73us/sample - loss: 2.6926 - acc: 0.4386 - val_loss: nan - val_acc: 0.5078\n",
            "Epoch 3/10\n",
            "110288/110288 [==============================] - 8s 74us/sample - loss: 2.0390 - acc: 0.5560 - val_loss: nan - val_acc: 0.6167\n",
            "Epoch 4/10\n",
            "110288/110288 [==============================] - 8s 73us/sample - loss: 1.4589 - acc: 0.6522 - val_loss: nan - val_acc: 0.6931\n",
            "Epoch 5/10\n",
            "110288/110288 [==============================] - 8s 73us/sample - loss: 1.1477 - acc: 0.7224 - val_loss: nan - val_acc: 0.7492\n",
            "Epoch 6/10\n",
            "110288/110288 [==============================] - 8s 73us/sample - loss: 0.9501 - acc: 0.7670 - val_loss: nan - val_acc: 0.7823\n",
            "Epoch 7/10\n",
            "110288/110288 [==============================] - 8s 73us/sample - loss: 0.8123 - acc: 0.7918 - val_loss: nan - val_acc: 0.8019\n",
            "Epoch 8/10\n",
            "110288/110288 [==============================] - 8s 74us/sample - loss: 0.7177 - acc: 0.8093 - val_loss: nan - val_acc: 0.8164\n",
            "Epoch 9/10\n",
            "110288/110288 [==============================] - 8s 73us/sample - loss: 0.6470 - acc: 0.8237 - val_loss: nan - val_acc: 0.8298\n",
            "Epoch 10/10\n",
            "110288/110288 [==============================] - 8s 73us/sample - loss: 0.5926 - acc: 0.8358 - val_loss: nan - val_acc: 0.8394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8fd18419b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZW9a1dXDlkI",
        "colab_type": "code",
        "outputId": "4a11a3f0-228d-4261-88c5-261a8e940fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(logits_to_text(simple_embedd_model.predict(tmp_x[:1])[0], french_tokenizer))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new jersey est parfois calme en l' et il il est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuUBViUXDiz8",
        "colab_type": "text"
      },
      "source": [
        "#**Bidirectional RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh52hqqbEQR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_bidirectional_model(input_shape, french_vocab_size):\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    bdd = Bidirectional(GRU(128, return_sequences = True, dropout = 0.1), input_shape = input_shape[1:])\n",
        "    logits = TimeDistributed(Dense(french_vocab_size, activation='softmax'))\n",
        "    \n",
        "    model.add(bdd)\n",
        "    model.add(logits)\n",
        "    \n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(1e-3), \n",
        "                 metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC_N_n8ZD5SP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_x = pad(processed_english, processed_french.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, processed_french.shape[-2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF__-dGbY3cD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a1e6ac5f-c573-4b56-981b-864d31ffce89"
      },
      "source": [
        "simple_bdd_model = simple_bidirectional_model(tmp_x.shape,  french_vocab_size+1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0625 08:52:32.487078 140256952489856 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0625 08:52:32.489733 140256952489856 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0625 08:52:32.491825 140256952489856 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJII7LBsZUNL",
        "colab_type": "code",
        "outputId": "e59141eb-003c-4f96-9360-c97cc68f2ea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "simple_bdd_model.fit(tmp_x, processed_french, batch_size=1024, epochs=20, validation_split=0.2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 110288 samples, validate on 27572 samples\n",
            "Epoch 1/20\n",
            "110288/110288 [==============================] - 15s 133us/sample - loss: 2.7254 - acc: 0.4996 - val_loss: 1.7869 - val_acc: 0.5696\n",
            "Epoch 2/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.6539 - acc: 0.5870 - val_loss: 1.4756 - val_acc: 0.6108\n",
            "Epoch 3/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.4474 - acc: 0.6146 - val_loss: 1.3557 - val_acc: 0.6266\n",
            "Epoch 4/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.3377 - acc: 0.6318 - val_loss: 1.2920 - val_acc: 0.6365\n",
            "Epoch 5/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.2631 - acc: 0.6454 - val_loss: 1.2606 - val_acc: 0.6337\n",
            "Epoch 6/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.2077 - acc: 0.6563 - val_loss: 1.2437 - val_acc: 0.6325\n",
            "Epoch 7/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.1634 - acc: 0.6644 - val_loss: 1.2643 - val_acc: 0.6313\n",
            "Epoch 8/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.1267 - acc: 0.6712 - val_loss: 1.2787 - val_acc: 0.6210\n",
            "Epoch 9/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.0946 - acc: 0.6766 - val_loss: 1.2682 - val_acc: 0.6281\n",
            "Epoch 10/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.0666 - acc: 0.6809 - val_loss: 1.2969 - val_acc: 0.6210\n",
            "Epoch 11/20\n",
            "110288/110288 [==============================] - 14s 124us/sample - loss: 1.0407 - acc: 0.6851 - val_loss: 1.3125 - val_acc: 0.6174\n",
            "Epoch 12/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 1.0182 - acc: 0.6891 - val_loss: 1.3696 - val_acc: 0.6137\n",
            "Epoch 13/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 0.9975 - acc: 0.6920 - val_loss: 1.4053 - val_acc: 0.6108\n",
            "Epoch 14/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 0.9799 - acc: 0.6947 - val_loss: 1.4543 - val_acc: 0.6012\n",
            "Epoch 15/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 0.9640 - acc: 0.6970 - val_loss: 1.4702 - val_acc: 0.6055\n",
            "Epoch 16/20\n",
            "110288/110288 [==============================] - 14s 124us/sample - loss: 0.9480 - acc: 0.7001 - val_loss: 1.4804 - val_acc: 0.6110\n",
            "Epoch 17/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 0.9341 - acc: 0.7020 - val_loss: 1.5375 - val_acc: 0.5978\n",
            "Epoch 18/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 0.9214 - acc: 0.7048 - val_loss: 1.6000 - val_acc: 0.5936\n",
            "Epoch 19/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 0.9104 - acc: 0.7064 - val_loss: 1.5765 - val_acc: 0.5958\n",
            "Epoch 20/20\n",
            "110288/110288 [==============================] - 14s 123us/sample - loss: 0.8993 - acc: 0.7085 - val_loss: 1.6481 - val_acc: 0.5917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8fcf2e4390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGJqTkqWZor6",
        "colab_type": "code",
        "outputId": "d5bae189-7cd4-4d11-c0a9-53b3708f7067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(logits_to_text(simple_bdd_model.predict(tmp_x[:1])[0], french_tokenizer))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new jersey est parfois froid au janvier mais il est agréable en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5QVJzAke6y1",
        "colab_type": "text"
      },
      "source": [
        "#***Encoder Decoder***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-oJI2AcJtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encdec_model(input_shape, output_sequence_length, french_vocab_size):\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(GRU(128, input_shape = input_shape[1:], return_sequences = False))\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    model.add(GRU(128, return_sequences = True))\n",
        "    model.add(TimeDistributed(Dense(french_vocab_size, activation = 'softmax')))\n",
        "\n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(1e-3), \n",
        "                 metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cfcIuP6cmvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_x = pad(processed_english)\n",
        "tmp_x = tmp_x.reshape((-1, processed_english.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxiaRCNecrCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enco_deco_model = encdec_model(\n",
        "    tmp_x.shape,\n",
        "    processed_french.shape[1],\n",
        "    french_vocab_size+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYOsuQgKc1Cd",
        "colab_type": "code",
        "outputId": "6333f80b-60fd-427e-e6c1-3dfee1dec76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "enco_deco_model.fit(tmp_x, processed_french, batch_size=1024, epochs=20, validation_split=0.2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 110288 samples, validate on 27572 samples\n",
            "Epoch 1/20\n",
            "110288/110288 [==============================] - 14s 125us/sample - loss: 3.0118 - acc: 0.4402 - val_loss: 2.4269 - val_acc: 0.4955\n",
            "Epoch 2/20\n",
            "110288/110288 [==============================] - 13s 116us/sample - loss: 2.2445 - acc: 0.5017 - val_loss: 2.0706 - val_acc: 0.5111\n",
            "Epoch 3/20\n",
            "110288/110288 [==============================] - 13s 115us/sample - loss: 1.9764 - acc: 0.5168 - val_loss: 1.9026 - val_acc: 0.5255\n",
            "Epoch 4/20\n",
            "110288/110288 [==============================] - 13s 115us/sample - loss: 1.8427 - acc: 0.5383 - val_loss: 1.7807 - val_acc: 0.5491\n",
            "Epoch 5/20\n",
            "110288/110288 [==============================] - 13s 116us/sample - loss: 1.7260 - acc: 0.5587 - val_loss: 1.6800 - val_acc: 0.5644\n",
            "Epoch 6/20\n",
            "110288/110288 [==============================] - 13s 116us/sample - loss: 1.6402 - acc: 0.5721 - val_loss: 1.6030 - val_acc: 0.5772\n",
            "Epoch 7/20\n",
            "110288/110288 [==============================] - 13s 115us/sample - loss: 1.5785 - acc: 0.5815 - val_loss: 1.5471 - val_acc: 0.5863\n",
            "Epoch 8/20\n",
            "110288/110288 [==============================] - 13s 114us/sample - loss: 1.5245 - acc: 0.5897 - val_loss: 1.5022 - val_acc: 0.5941\n",
            "Epoch 9/20\n",
            "110288/110288 [==============================] - 13s 114us/sample - loss: 1.4790 - acc: 0.5979 - val_loss: 1.4540 - val_acc: 0.6036\n",
            "Epoch 10/20\n",
            "110288/110288 [==============================] - 13s 115us/sample - loss: 1.4367 - acc: 0.6071 - val_loss: 1.4149 - val_acc: 0.6140\n",
            "Epoch 11/20\n",
            "110288/110288 [==============================] - 13s 114us/sample - loss: 1.4012 - acc: 0.6158 - val_loss: 1.3883 - val_acc: 0.6178\n",
            "Epoch 12/20\n",
            "110288/110288 [==============================] - 13s 115us/sample - loss: 1.3718 - acc: 0.6207 - val_loss: 1.3568 - val_acc: 0.6243\n",
            "Epoch 13/20\n",
            "110288/110288 [==============================] - 13s 115us/sample - loss: 1.3465 - acc: 0.6254 - val_loss: 1.3495 - val_acc: 0.6194\n",
            "Epoch 14/20\n",
            "110288/110288 [==============================] - 13s 115us/sample - loss: 1.3269 - acc: 0.6299 - val_loss: 1.3245 - val_acc: 0.6278\n",
            "Epoch 15/20\n",
            "110288/110288 [==============================] - 13s 114us/sample - loss: 1.3093 - acc: 0.6335 - val_loss: 1.2975 - val_acc: 0.6360\n",
            "Epoch 16/20\n",
            "110288/110288 [==============================] - 13s 114us/sample - loss: 1.2890 - acc: 0.6365 - val_loss: 1.2811 - val_acc: 0.6375\n",
            "Epoch 17/20\n",
            "110288/110288 [==============================] - 13s 114us/sample - loss: 1.2768 - acc: 0.6375 - val_loss: 1.2712 - val_acc: 0.6394\n",
            "Epoch 18/20\n",
            "110288/110288 [==============================] - 13s 114us/sample - loss: 1.2654 - acc: 0.6391 - val_loss: 1.2536 - val_acc: 0.6403\n",
            "Epoch 19/20\n",
            "110288/110288 [==============================] - 13s 114us/sample - loss: 1.2576 - acc: 0.6404 - val_loss: 1.2437 - val_acc: 0.6442\n",
            "Epoch 20/20\n",
            "110288/110288 [==============================] - 13s 114us/sample - loss: 1.2454 - acc: 0.6436 - val_loss: 1.2213 - val_acc: 0.6497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8fcdeabfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8b6LiXEs7_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "19a3ff5a-7e10-491a-924b-178d2f681dd7"
      },
      "source": [
        "print(logits_to_text(enco_deco_model.predict(tmp_x[:10])[2], french_tokenizer))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "la est jamais agréable en mois et il est est est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xpSoRbUVwC-",
        "colab_type": "text"
      },
      "source": [
        "# *Custom*\n",
        "\n",
        "Create a model that incorporates embedding and a bidirectional RNN into one model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSMG6Uq8c_8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    embed_layer = Embedding(input_dim = english_vocab_size, output_dim = 128, input_length = input_shape[1])\n",
        "    bd_layer_1 = Bidirectional(GRU(256, return_sequences = False))\n",
        "    repeat_vector_1 = RepeatVector(output_sequence_length)\n",
        "    bd_layer_2 = Bidirectional(GRU(256, return_sequences = True))\n",
        "    time_distributed = TimeDistributed(Dense(french_vocab_size, activation = 'softmax'))\n",
        "    \n",
        "    model.add(embed_layer)\n",
        "    model.add(bd_layer_1)\n",
        "    model.add(repeat_vector_1)\n",
        "    model.add(bd_layer_2)\n",
        "    model.add(time_distributed)\n",
        "    \n",
        "    model.compile(loss = sparse_categorical_crossentropy, \n",
        "                 optimizer = Adam(5e-3), \n",
        "                 metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRXEDNBVYu4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_x = pad(processed_english)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXbG_wFXZPyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_model = final_model(tmp_x.shape, processed_french.shape[1], english_vocab_size + 1, french_vocab_size + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrX-U0rxZhTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "72d8f3fe-dabc-4a4c-80e1-c54d0b715fb2"
      },
      "source": [
        "custom_model.fit(tmp_x, processed_french, batch_size = 1024, epochs = 18, validation_split = 0.2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 110288 samples, validate on 27572 samples\n",
            "Epoch 1/18\n",
            "110288/110288 [==============================] - 42s 380us/sample - loss: 2.0001 - acc: 0.5325 - val_loss: 1.3340 - val_acc: 0.6487\n",
            "Epoch 2/18\n",
            "110288/110288 [==============================] - 40s 361us/sample - loss: 1.0771 - acc: 0.6994 - val_loss: 0.8941 - val_acc: 0.7406\n",
            "Epoch 3/18\n",
            "110288/110288 [==============================] - 40s 360us/sample - loss: 0.7234 - acc: 0.7854 - val_loss: 0.5657 - val_acc: 0.8275\n",
            "Epoch 4/18\n",
            "110288/110288 [==============================] - 40s 360us/sample - loss: 0.4645 - acc: 0.8608 - val_loss: 0.3389 - val_acc: 0.9027\n",
            "Epoch 5/18\n",
            "110288/110288 [==============================] - 40s 364us/sample - loss: 0.2702 - acc: 0.9221 - val_loss: 0.2201 - val_acc: 0.9360\n",
            "Epoch 6/18\n",
            "110288/110288 [==============================] - 40s 359us/sample - loss: 0.1796 - acc: 0.9480 - val_loss: 0.1561 - val_acc: 0.9555\n",
            "Epoch 7/18\n",
            "110288/110288 [==============================] - 40s 361us/sample - loss: 0.1394 - acc: 0.9590 - val_loss: 0.1348 - val_acc: 0.9602\n",
            "Epoch 8/18\n",
            "110288/110288 [==============================] - 40s 363us/sample - loss: 0.1190 - acc: 0.9651 - val_loss: 0.1291 - val_acc: 0.9624\n",
            "Epoch 9/18\n",
            "110288/110288 [==============================] - 40s 364us/sample - loss: 0.1026 - acc: 0.9695 - val_loss: 0.1159 - val_acc: 0.9659\n",
            "Epoch 10/18\n",
            "110288/110288 [==============================] - 40s 364us/sample - loss: 0.0829 - acc: 0.9754 - val_loss: 0.0921 - val_acc: 0.9721\n",
            "Epoch 11/18\n",
            "110288/110288 [==============================] - 40s 363us/sample - loss: 0.0752 - acc: 0.9777 - val_loss: 0.0922 - val_acc: 0.9735\n",
            "Epoch 12/18\n",
            "110288/110288 [==============================] - 40s 364us/sample - loss: 0.0644 - acc: 0.9808 - val_loss: 0.0843 - val_acc: 0.9751\n",
            "Epoch 13/18\n",
            "110288/110288 [==============================] - 40s 363us/sample - loss: 0.0681 - acc: 0.9797 - val_loss: 0.0889 - val_acc: 0.9740\n",
            "Epoch 14/18\n",
            "110288/110288 [==============================] - 40s 360us/sample - loss: 0.0622 - acc: 0.9814 - val_loss: 0.0723 - val_acc: 0.9792\n",
            "Epoch 15/18\n",
            "110288/110288 [==============================] - 40s 361us/sample - loss: 0.0472 - acc: 0.9857 - val_loss: 0.0744 - val_acc: 0.9785\n",
            "Epoch 16/18\n",
            "110288/110288 [==============================] - 40s 364us/sample - loss: 0.0462 - acc: 0.9863 - val_loss: 0.0666 - val_acc: 0.9814\n",
            "Epoch 17/18\n",
            "110288/110288 [==============================] - 40s 360us/sample - loss: 0.0505 - acc: 0.9849 - val_loss: 0.0927 - val_acc: 0.9731\n",
            "Epoch 18/18\n",
            "110288/110288 [==============================] - 40s 364us/sample - loss: 0.0451 - acc: 0.9863 - val_loss: 0.0737 - val_acc: 0.9793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f8189c9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laweHuXmZsLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f08b684-bafa-4b03-f798-a50b71d31f78"
      },
      "source": [
        "print(logits_to_text(custom_model.predict(tmp_x[:10])[2], french_tokenizer))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "california est généralement calme en mars et il est généralement chaud en juin <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgvP7zuxtnXd",
        "colab_type": "text"
      },
      "source": [
        "# *LSTM*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsjH9b5dtuYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_model(input_shape, french_vocab_size):\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    embedding = Embedding(french_vocab_size, 64, input_length = input_shape[1])\n",
        "    lstm_layer_1 = CuDNNLSTM(64, return_sequences = True)\n",
        "    logits = TimeDistributed(Dense(french_vocab_size, activation = 'softmax'))\n",
        "    \n",
        "    model.add(embedding)\n",
        "    model.add(lstm_layer_1)\n",
        "    model.add(logits)\n",
        "    \n",
        "    model.compile(loss = sparse_categorical_crossentropy, optimizer = Adam(5e-3), metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ep_8qaumN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp_x = pad(processed_english, max_french_sequence_length)\n",
        "tmp_x = tmp_x.reshape((-1, processed_french.shape[-2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEMHsUw8umQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simple_lstm_model = lstm_model(tmp_x.shape, french_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBfkQv0OumTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0176733f-157c-45ff-aa7b-d7ae5758d21c"
      },
      "source": [
        "simple_lstm_model.fit(tmp_x, processed_french, batch_size=1024, epochs=80, validation_split=0.2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 110288 samples, validate on 27572 samples\n",
            "Epoch 1/80\n",
            "110288/110288 [==============================] - 4s 39us/sample - loss: 2.8838 - acc: 0.4525 - val_loss: nan - val_acc: 0.5536\n",
            "Epoch 2/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 1.4746 - acc: 0.6364 - val_loss: nan - val_acc: 0.7236\n",
            "Epoch 3/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.8894 - acc: 0.7675 - val_loss: nan - val_acc: 0.7969\n",
            "Epoch 4/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.6417 - acc: 0.8168 - val_loss: nan - val_acc: 0.8364\n",
            "Epoch 5/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.5209 - acc: 0.8462 - val_loss: nan - val_acc: 0.8584\n",
            "Epoch 6/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.4487 - acc: 0.8652 - val_loss: nan - val_acc: 0.8723\n",
            "Epoch 7/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.4016 - acc: 0.8778 - val_loss: nan - val_acc: 0.8833\n",
            "Epoch 8/80\n",
            "110288/110288 [==============================] - 3s 31us/sample - loss: 0.3654 - acc: 0.8878 - val_loss: nan - val_acc: 0.8924\n",
            "Epoch 9/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.3406 - acc: 0.8951 - val_loss: nan - val_acc: 0.8976\n",
            "Epoch 10/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.3193 - acc: 0.9012 - val_loss: nan - val_acc: 0.9023\n",
            "Epoch 11/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.3025 - acc: 0.9060 - val_loss: nan - val_acc: 0.9082\n",
            "Epoch 12/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2890 - acc: 0.9096 - val_loss: nan - val_acc: 0.9118\n",
            "Epoch 13/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2771 - acc: 0.9128 - val_loss: nan - val_acc: 0.9141\n",
            "Epoch 14/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2682 - acc: 0.9150 - val_loss: nan - val_acc: 0.9159\n",
            "Epoch 15/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2587 - acc: 0.9176 - val_loss: nan - val_acc: 0.9178\n",
            "Epoch 16/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2524 - acc: 0.9190 - val_loss: nan - val_acc: 0.9190\n",
            "Epoch 17/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2454 - acc: 0.9212 - val_loss: nan - val_acc: 0.9207\n",
            "Epoch 18/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2400 - acc: 0.9226 - val_loss: nan - val_acc: 0.9222\n",
            "Epoch 19/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2347 - acc: 0.9238 - val_loss: nan - val_acc: 0.9230\n",
            "Epoch 20/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2312 - acc: 0.9246 - val_loss: nan - val_acc: 0.9242\n",
            "Epoch 21/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2267 - acc: 0.9258 - val_loss: nan - val_acc: 0.9250\n",
            "Epoch 22/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2214 - acc: 0.9274 - val_loss: nan - val_acc: 0.9259\n",
            "Epoch 23/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2189 - acc: 0.9279 - val_loss: nan - val_acc: 0.9259\n",
            "Epoch 24/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2150 - acc: 0.9290 - val_loss: nan - val_acc: 0.9268\n",
            "Epoch 25/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2133 - acc: 0.9292 - val_loss: nan - val_acc: 0.9285\n",
            "Epoch 26/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2094 - acc: 0.9304 - val_loss: nan - val_acc: 0.9276\n",
            "Epoch 27/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2087 - acc: 0.9304 - val_loss: nan - val_acc: 0.9283\n",
            "Epoch 28/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2045 - acc: 0.9315 - val_loss: nan - val_acc: 0.9294\n",
            "Epoch 29/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2032 - acc: 0.9318 - val_loss: nan - val_acc: 0.9294\n",
            "Epoch 30/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2025 - acc: 0.9318 - val_loss: nan - val_acc: 0.9303\n",
            "Epoch 31/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.2002 - acc: 0.9326 - val_loss: nan - val_acc: 0.9294\n",
            "Epoch 32/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1984 - acc: 0.9329 - val_loss: nan - val_acc: 0.9303\n",
            "Epoch 33/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1986 - acc: 0.9327 - val_loss: nan - val_acc: 0.9297\n",
            "Epoch 34/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1986 - acc: 0.9326 - val_loss: nan - val_acc: 0.9301\n",
            "Epoch 35/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1952 - acc: 0.9336 - val_loss: nan - val_acc: 0.9310\n",
            "Epoch 36/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1938 - acc: 0.9339 - val_loss: nan - val_acc: 0.9313\n",
            "Epoch 37/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1915 - acc: 0.9345 - val_loss: nan - val_acc: 0.9322\n",
            "Epoch 38/80\n",
            "110288/110288 [==============================] - 3s 31us/sample - loss: 0.1903 - acc: 0.9349 - val_loss: nan - val_acc: 0.9318\n",
            "Epoch 39/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1898 - acc: 0.9348 - val_loss: nan - val_acc: 0.9322\n",
            "Epoch 40/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1904 - acc: 0.9345 - val_loss: nan - val_acc: 0.9308\n",
            "Epoch 41/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1879 - acc: 0.9352 - val_loss: nan - val_acc: 0.9325\n",
            "Epoch 42/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1857 - acc: 0.9358 - val_loss: nan - val_acc: 0.9332\n",
            "Epoch 43/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1848 - acc: 0.9362 - val_loss: nan - val_acc: 0.9325\n",
            "Epoch 44/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1844 - acc: 0.9363 - val_loss: nan - val_acc: 0.9335\n",
            "Epoch 45/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1836 - acc: 0.9365 - val_loss: nan - val_acc: 0.9337\n",
            "Epoch 46/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1844 - acc: 0.9361 - val_loss: nan - val_acc: 0.9322\n",
            "Epoch 47/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1854 - acc: 0.9357 - val_loss: nan - val_acc: 0.9329\n",
            "Epoch 48/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1842 - acc: 0.9360 - val_loss: nan - val_acc: 0.9340\n",
            "Epoch 49/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1812 - acc: 0.9370 - val_loss: nan - val_acc: 0.9340\n",
            "Epoch 50/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1802 - acc: 0.9371 - val_loss: nan - val_acc: 0.9345\n",
            "Epoch 51/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1790 - acc: 0.9374 - val_loss: nan - val_acc: 0.9338\n",
            "Epoch 52/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1783 - acc: 0.9376 - val_loss: nan - val_acc: 0.9340\n",
            "Epoch 53/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1774 - acc: 0.9378 - val_loss: nan - val_acc: 0.9341\n",
            "Epoch 54/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1809 - acc: 0.9367 - val_loss: nan - val_acc: 0.9329\n",
            "Epoch 55/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1780 - acc: 0.9376 - val_loss: nan - val_acc: 0.9340\n",
            "Epoch 56/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1769 - acc: 0.9378 - val_loss: nan - val_acc: 0.9324\n",
            "Epoch 57/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1792 - acc: 0.9371 - val_loss: nan - val_acc: 0.9338\n",
            "Epoch 58/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1755 - acc: 0.9382 - val_loss: nan - val_acc: 0.9340\n",
            "Epoch 59/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1758 - acc: 0.9381 - val_loss: nan - val_acc: 0.9343\n",
            "Epoch 60/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1751 - acc: 0.9383 - val_loss: nan - val_acc: 0.9343\n",
            "Epoch 61/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1761 - acc: 0.9379 - val_loss: nan - val_acc: 0.9351\n",
            "Epoch 62/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1752 - acc: 0.9381 - val_loss: nan - val_acc: 0.9340\n",
            "Epoch 63/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1754 - acc: 0.9381 - val_loss: nan - val_acc: 0.9349\n",
            "Epoch 64/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1739 - acc: 0.9384 - val_loss: nan - val_acc: 0.9349\n",
            "Epoch 65/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1783 - acc: 0.9372 - val_loss: nan - val_acc: 0.9340\n",
            "Epoch 66/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1743 - acc: 0.9383 - val_loss: nan - val_acc: 0.9351\n",
            "Epoch 67/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1720 - acc: 0.9390 - val_loss: nan - val_acc: 0.9348\n",
            "Epoch 68/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1736 - acc: 0.9385 - val_loss: nan - val_acc: 0.9353\n",
            "Epoch 69/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1723 - acc: 0.9389 - val_loss: nan - val_acc: 0.9344\n",
            "Epoch 70/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1715 - acc: 0.9392 - val_loss: nan - val_acc: 0.9352\n",
            "Epoch 71/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1709 - acc: 0.9392 - val_loss: nan - val_acc: 0.9356\n",
            "Epoch 72/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1703 - acc: 0.9394 - val_loss: nan - val_acc: 0.9348\n",
            "Epoch 73/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1714 - acc: 0.9388 - val_loss: nan - val_acc: 0.9343\n",
            "Epoch 74/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1712 - acc: 0.9390 - val_loss: nan - val_acc: 0.9350\n",
            "Epoch 75/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1701 - acc: 0.9393 - val_loss: nan - val_acc: 0.9351\n",
            "Epoch 76/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1702 - acc: 0.9393 - val_loss: nan - val_acc: 0.9358\n",
            "Epoch 77/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1707 - acc: 0.9391 - val_loss: nan - val_acc: 0.9346\n",
            "Epoch 78/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1703 - acc: 0.9393 - val_loss: nan - val_acc: 0.9348\n",
            "Epoch 79/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1701 - acc: 0.9392 - val_loss: nan - val_acc: 0.9348\n",
            "Epoch 80/80\n",
            "110288/110288 [==============================] - 3s 30us/sample - loss: 0.1717 - acc: 0.9387 - val_loss: nan - val_acc: 0.9354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f80d461d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y1ALUfDumVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9661beb-45e4-4faf-8633-be7816bfc814"
      },
      "source": [
        "print(logits_to_text(simple_lstm_model.predict(tmp_x[:1])[0], french_tokenizer))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new jersey est parfois calme en l' et et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29s8yvmh24Io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}